{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtpgMXSXDBXmse/PuHrm/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredmarko/Library/blob/main/ICR_Identifying_Age_Related_Conditions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LB0YQHg4kt27"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first few rows of the training data\n",
        "print(train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImnO0NpylCvT",
        "outputId": "1937b7eb-5de9-4da3-da13-040d1fb4c5d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Id        AB          AF          AH         AM        AR  \\\n",
            "0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n",
            "1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n",
            "2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n",
            "3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n",
            "4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n",
            "\n",
            "         AX        AY         AZ          BC  ...        FL        FR  \\\n",
            "0  0.699861  0.025578   9.812214    5.555634  ...  7.298162   1.73855   \n",
            "1  3.632190  0.025578  13.517790    1.229900  ...  0.173229   0.49706   \n",
            "2  6.732840  0.025578  12.824570    1.229900  ...  7.709560   0.97556   \n",
            "3  3.685344  0.025578  11.053708    1.229900  ...  6.122162   0.49706   \n",
            "4  3.942255  0.054810   3.396778  102.151980  ...  8.153058  48.50134   \n",
            "\n",
            "         FS         GB          GE            GF         GH         GI  \\\n",
            "0  0.094822  11.339138   72.611063   2003.810319  22.136229  69.834944   \n",
            "1  0.568932   9.292698   72.611063  27981.562750  29.135430  32.131996   \n",
            "2  1.198821  37.077772   88.609437  13676.957810  28.022851  35.192676   \n",
            "3  0.284466  18.529584   82.416803   2094.262452  39.948656  90.493248   \n",
            "4  0.121914  16.408728  146.109943   8524.370502  45.381316  36.262628   \n",
            "\n",
            "          GL  Class  \n",
            "0   0.120343      1  \n",
            "1  21.978000      0  \n",
            "2   0.196941      0  \n",
            "3   0.155829      0  \n",
            "4   0.096614      1  \n",
            "\n",
            "[5 rows x 58 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first few rows of the test data\n",
        "print(test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gqr3vP4lN1y",
        "outputId": "9a815ac4-0d25-4d39-ba96-0ece901a1b10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Id   AB   AF   AH   AM   AR   AX   AY   AZ   BC  ...   FI   FL  \\\n",
            "0  00eed32682bb  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
            "1  010ebe33f668  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
            "2  02fa521e1838  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
            "3  040e15f562a2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
            "4  046e85c7cc7f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
            "\n",
            "    FR   FS   GB   GE   GF   GH   GI   GL  \n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[5 rows x 57 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the data\n",
        "print(\"Train data shape:\", train.shape)\n",
        "print(\"Test data shape:\", test.shape)\n",
        "\n",
        "# Print the columns of the data\n",
        "print(\"Train data columns:\", train.columns)\n",
        "print(\"Test data columns:\", test.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8YY_tsUlSYY",
        "outputId": "75d8e9ab-7c96-4071-9615-1fc109a988b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (617, 58)\n",
            "Test data shape: (5, 57)\n",
            "Train data columns: Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
            "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
            "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
            "       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
            "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'],\n",
            "      dtype='object')\n",
            "Test data columns: Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
            "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
            "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
            "       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
            "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for the training data\n",
        "print(train.describe())\n",
        "\n",
        "# Summary statistics for the test data\n",
        "print(test.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEf_q9xdlbI3",
        "outputId": "c691dd15-1de4-4e28-b99c-5fd1882024ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               AB            AF           AH          AM          AR  \\\n",
            "count  617.000000    617.000000   617.000000  617.000000  617.000000   \n",
            "mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n",
            "std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n",
            "min      0.081187    192.593280    85.200147    3.177522    8.138688   \n",
            "25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n",
            "50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n",
            "75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n",
            "max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n",
            "\n",
            "               AX          AY          AZ           BC           BD   ...  \\\n",
            "count  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \n",
            "mean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \n",
            "std      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \n",
            "min      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n",
            "25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n",
            "50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n",
            "75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \n",
            "max     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n",
            "\n",
            "               FL           FR          FS          GB           GE  \\\n",
            "count  616.000000   617.000000  615.000000  617.000000   617.000000   \n",
            "mean     5.433199     3.533905    0.421501   20.724856   131.714987   \n",
            "std     11.496257    50.181948    1.305365    9.991907   144.181524   \n",
            "min      0.173229     0.497060    0.067730    4.102182    72.611063   \n",
            "25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n",
            "50%      3.028141     1.131000    0.250601   18.771436    72.611063   \n",
            "75%      6.238814     1.512060    0.535067   25.608406   127.591671   \n",
            "max    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n",
            "\n",
            "                  GF          GH          GI          GL       Class  \n",
            "count     617.000000  617.000000  617.000000  616.000000  617.000000  \n",
            "mean    14679.595398   31.489716   50.584437    8.530961    0.175041  \n",
            "std     19352.959387    9.864239   36.266251   10.327010    0.380310  \n",
            "min        13.038894    9.432735    0.897628    0.001129    0.000000  \n",
            "25%      2798.992584   25.034888   23.011684    0.124392    0.000000  \n",
            "50%      7838.273610   30.608946   41.007968    0.337827    0.000000  \n",
            "75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \n",
            "max    143790.071200   81.210825  191.194764   21.978000    1.000000  \n",
            "\n",
            "[8 rows x 56 columns]\n",
            "        AB   AF   AH   AM   AR   AX   AY   AZ   BC  BD   ...   FI   FL   FR  \\\n",
            "count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  ...  5.0  5.0  5.0   \n",
            "mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "\n",
            "        FS   GB   GE   GF   GH   GI   GL  \n",
            "count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  \n",
            "mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[8 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the training data\n",
        "print(train.isnull().sum())\n",
        "\n",
        "# Check for missing values in the test data\n",
        "print(test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpX_J9zqlg6j",
        "outputId": "c831458e-25d3-41a9-d3ab-ddb17acee4d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id        0\n",
            "AB        0\n",
            "AF        0\n",
            "AH        0\n",
            "AM        0\n",
            "AR        0\n",
            "AX        0\n",
            "AY        0\n",
            "AZ        0\n",
            "BC        0\n",
            "BD        0\n",
            "BN        0\n",
            "BP        0\n",
            "BQ       60\n",
            "BR        0\n",
            "BZ        0\n",
            "CB        2\n",
            "CC        3\n",
            "CD        0\n",
            "CF        0\n",
            "CH        0\n",
            "CL        0\n",
            "CR        0\n",
            "CS        0\n",
            "CU        0\n",
            "CW        0\n",
            "DA        0\n",
            "DE        0\n",
            "DF        0\n",
            "DH        0\n",
            "DI        0\n",
            "DL        0\n",
            "DN        0\n",
            "DU        1\n",
            "DV        0\n",
            "DY        0\n",
            "EB        0\n",
            "EE        0\n",
            "EG        0\n",
            "EH        0\n",
            "EJ        0\n",
            "EL       60\n",
            "EP        0\n",
            "EU        0\n",
            "FC        1\n",
            "FD        0\n",
            "FE        0\n",
            "FI        0\n",
            "FL        1\n",
            "FR        0\n",
            "FS        2\n",
            "GB        0\n",
            "GE        0\n",
            "GF        0\n",
            "GH        0\n",
            "GI        0\n",
            "GL        1\n",
            "Class     0\n",
            "dtype: int64\n",
            "Id     0\n",
            "AB     0\n",
            "AF     0\n",
            "AH     0\n",
            "AM     0\n",
            "AR     0\n",
            "AX     0\n",
            "AY     0\n",
            "AZ     0\n",
            "BC     0\n",
            "BD     0\n",
            "BN     0\n",
            "BP     0\n",
            "BQ     0\n",
            "BR     0\n",
            "BZ     0\n",
            "CB     0\n",
            "CC     0\n",
            "CD     0\n",
            "CF     0\n",
            "CH     0\n",
            "CL     0\n",
            "CR     0\n",
            "CS     0\n",
            "CU     0\n",
            "CW     0\n",
            "DA     0\n",
            "DE     0\n",
            "DF     0\n",
            "DH     0\n",
            "DI     0\n",
            "DL     0\n",
            "DN     0\n",
            "DU     0\n",
            "DV     0\n",
            "DY     0\n",
            "EB     0\n",
            "EE     0\n",
            "EG     0\n",
            "EH     0\n",
            "EJ     0\n",
            "EL     0\n",
            "EP     0\n",
            "EU     0\n",
            "FC     0\n",
            "FD     0\n",
            "FE     0\n",
            "FI     0\n",
            "FL     0\n",
            "FR     0\n",
            "FS     0\n",
            "GB     0\n",
            "GE     0\n",
            "GF     0\n",
            "GH     0\n",
            "GI     0\n",
            "GL     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of target variable in training data\n",
        "print(train['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4sl2b2nloBj",
        "outputId": "1f555a90-ece8-4292-c56f-6af35ebcdb55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    509\n",
            "1    108\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the median\n",
        "train = train.fillna(train.median())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgXlYkWvlsJl",
        "outputId": "81ff39de-77f3-436a-9f1d-4feae02565d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-07b2541353eb>:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  train = train.fillna(train.median())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "X = train.drop(columns=['Id', 'Class'])\n",
        "\n",
        "# Target\n",
        "y = train['Class']"
      ],
      "metadata": {
        "id": "Dq8QTwV1p0Sf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate 'EJ' column\n",
        "EJ_train = X['EJ']\n",
        "\n",
        "# Drop 'EJ' column from the features\n",
        "X = X.drop(columns='EJ')"
      ],
      "metadata": {
        "id": "sSw6yL7zmjtH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize a scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on the training data\n",
        "scaler.fit(X)\n",
        "\n",
        "# Transform the training data\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "# Replace features with their scaled versions\n",
        "X = pd.DataFrame(X_scaled, columns=X.columns)"
      ],
      "metadata": {
        "id": "OpKacXEMm0bb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 'EJ' back to the dataframe\n",
        "X['EJ'] = EJ_train.values"
      ],
      "metadata": {
        "id": "ABLH1IjJnCEF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data for model validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WW1vri__ndLD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# LightGBM can handle categorical features but they must be encoded as integers, not strings\n",
        "# So we'll use LabelEncoder from sklearn to transform the 'EJ' column\n",
        "le = LabelEncoder()\n",
        "X_train['EJ'] = le.fit_transform(X_train['EJ'])\n",
        "X_val['EJ'] = le.transform(X_val['EJ'])  # apply same transformation to validation set\n",
        "\n",
        "# Convert your data into LightGBM Dataset format\n",
        "dtrain = lgb.Dataset(X_train, label=y_train, categorical_feature=['EJ'])\n",
        "\n",
        "# Define your parameters\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'verbose': -1,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Train your model\n",
        "model = lgb.train(params, dtrain, num_boost_round=1000)\n",
        "\n",
        "# Predict on your validation set\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# You can use these predictions to assess your model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx-CsNY3nhXa",
        "outputId": "4f419858-130d-4b36-a905-9c4dd0f75dc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
            "  _log_warning('Using categorical_feature in Dataset.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate 'Id' and 'EJ' columns\n",
        "test_ids = test['Id']\n",
        "EJ_test = test['EJ']\n",
        "\n",
        "# Drop 'Id' and 'EJ' columns from the test features\n",
        "test = test.drop(columns=['Id', 'EJ'])\n",
        "\n",
        "# Handle missing values\n",
        "# Assuming you're filling numerical missing values with the median\n",
        "test = test.fillna(train.median())\n",
        "\n",
        "# Standardize the rest of the columns\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# Replace columns with their scaled versions\n",
        "test = pd.DataFrame(test_scaled, columns=test.columns)\n",
        "\n",
        "# Transform 'EJ' column using the LabelEncoder and re-assign it\n",
        "EJ_test = le.transform(EJ_test)\n",
        "test['EJ'] = EJ_test\n",
        "\n",
        "# Re-assign 'Id' column\n",
        "test['Id'] = test_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WZPJ26Qodx7",
        "outputId": "6aef3666-3159-4312-9de8-060208e72a38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-bae2495d5530>:10: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  test = test.fillna(train.median())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your validation features and labels into a LightGBM Dataset\n",
        "dval = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "# Use your trained model to make predictions on your validation set\n",
        "y_pred = model.predict(dval.data)"
      ],
      "metadata": {
        "id": "voGroOb4q9ai"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Assume that you've made predictions on your validation set\n",
        "# and that they're stored in a variable named y_pred\n",
        "\n",
        "# Calculate log loss\n",
        "logloss = log_loss(y_val, y_pred)\n",
        "print(\"Log Loss: \", logloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLkNBiA4rKTs",
        "outputId": "835cd520-e4ad-4bbf-dc7d-e4057eb967c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss:  0.20790042744790918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.05, 0.01],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Create a new instance of LGBMClassifier\n",
        "model = lgb.LGBMClassifier()\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "3-spInRJronB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)\n",
        "print(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CH4pUVps57a",
        "outputId": "ddf19586-0551-4354-d842-be2006aa6926"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}\n",
            "LGBMClassifier(learning_rate=0.05, max_depth=3, n_estimators=200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Create an instance of LGBMClassifier with the best hyperparameters\n",
        "model = lgb.LGBMClassifier(learning_rate=0.05, max_depth=3, n_estimators=200)\n",
        "\n",
        "# Train your model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = model.predict_proba(X_val)\n",
        "\n",
        "# Calculate log loss\n",
        "logloss = log_loss(y_val, y_pred)\n",
        "print(\"Log Loss: \", logloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0G-0gS2tTr7",
        "outputId": "772e82f9-67c7-47d7-a08d-e465ed9c0a44"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss:  0.14247618788087021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBClassifier(...)\n",
        "# Rest of the code remains the same\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Convert your training data into XGBoost's DMatrix format\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "# Define the parameters for XGBoost\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'eta': 0.1,\n",
        "    'max_depth': 3,\n",
        "    'min_child_weight': 1,\n",
        "    'gamma': 0,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "# Convert your validation data into XGBoost's DMatrix format\n",
        "dval = xgb.DMatrix(X_val)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred = model.predict(dval)\n",
        "\n",
        "# Calculate log loss on the validation set\n",
        "logloss = log_loss(y_val, y_val_pred)\n",
        "print(\"Log Loss: \", logloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxz1zrhnuaCy",
        "outputId": "8bee05c5-e713-428e-fde5-1ed60c714adc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:617: FutureWarning: Pass `objective` as keyword args.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss:  0.12676985632426066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Convert your training data into XGBoost's DMatrix format\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'eta': [0.1, 0.05, 0.01],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'gamma': [0, 0.5, 1],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Define the model\n",
        "model = xgb.XGBClassifier(objective='binary:logistic', seed=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, scoring='neg_log_loss', cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the validation set using the best model\n",
        "y_val_pred_proba = best_model.predict_proba(X_val)\n",
        "\n",
        "# Extract the predicted probabilities for the positive class\n",
        "y_val_pred = y_val_pred_proba[:, 1]\n",
        "\n",
        "# Calculate log loss on the validation set\n",
        "logloss = log_loss(y_val, y_val_pred)\n",
        "print(\"Log Loss: \", logloss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdSbudqWu4pq",
        "outputId": "c0ff5e8c-6955-404c-9931-8017e5e0f681"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss:  0.15662187522781837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iinjmzXZveYO"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}